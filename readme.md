### Transformer playground

This is my playground with [Transformer](https://arxiv.org/abs/1706.03762) seq2seq model implementation in PyTorch. 
Implementation is basically taken from excellent [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html) guide, refactored, updated for pytorch 0.4 and more commented. 

Update:  
* Beam Search implementation inspired by implementation in openNMT have been added.
